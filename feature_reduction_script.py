# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


# %% [markdown]
# ### Reduction methods as functions with parameters are given below.

# %% [markdown]
# ##### 1. Creating a Correlation matrix and detecting highly correlated variables

# %%
''' returns a dataframe with all the correlated columns removed. (Only one of them left remaining)
removals is used to remove important columns beforehand and then add them back later after the removal process. (to avoid removing important columns '''
def Reduce_by_correlation(df, max_correlation= 0.9,  removals=[]):
    rem = []
    for name in removals:
        rem.append(df[name]); 
        df = df.drop(name, axis=1); 
    cor_matrix = df.corr().abs()
    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))
    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > max_correlation)]
    df = df.drop(df[to_drop], axis=1)
    for i in range(0, len(rem)):
        df.insert(i, removals[i], rem[i])    
    return df


# %% [markdown]
# #### 2. Identifying features that have low support
# We know that features that have low support would not be much useful to us. 
# Even then it may be important to keep features which only appear in malicious apps, even if with very low support as they may be good identifiers of some types of malware. For this we have a danger threshold which states that if the samples which have this feature have this much % of just malware apps, then we do not remove this feature.

# %%

def Reduce_by_support( df, min_support = 0.1, removals=[],danger_threshold = 0.95, should_drop_possibly_dangerous = True):
    rem = []
    for name in removals:
        rem.append(df[name]); 
        df = df.drop(name, axis=1); 
    
    supported_features = df; 
    dropping_features_through_support = []

    # possibly_dangerous_features = []; 
    #if malware/(benign + malware) is greater than this ratio, then we can classify it as a potentially dangerous feature.

    #if this is set to true, then we will drop the low support features even if they are labelled as possibly dangerous.
    totalMal = supported_features['isMalware'].sum()
    totalBen = len(supported_features['isMalware']) - totalMal; 

    possibly_dangerous_features  =[] 
    for column in supported_features.columns:
        if(column == "isMalware" or column == "Name" or column == "Activities" or column == "Services" or 
        column == "Permissions" or column == "Actions" or column == "receivers" or column == "Categories" ):
            continue #we don't want to remove these columns anyway. 
        malSum = 0; 
        benSum = 0;   
        curCol = supported_features[column]
        for i in range(0, len(curCol)):
            if(curCol[i] == 1 and supported_features['isMalware'][i] == 1):
                malSum += 1
            elif(curCol[i] == 1 and supported_features['isMalware'][i] == 0):
                benSum += 1
        
        dangerProb = (malSum/totalMal) / (malSum/totalMal + benSum/totalBen) 
        #now that we know the individual sums for malwares and benign applications, we can further reduce the features by thus deciding on a threshold.
        if(dangerProb >= danger_threshold):
            possibly_dangerous_features.append(column)
        if(malSum + benSum < min_support*supported_features.shape[0]):
            if((benSum >= malSum*(1-danger_threshold)) and not should_drop_possibly_dangerous) or (should_drop_possibly_dangerous == True):
                dropping_features_through_support.append(column)

    supported_features = supported_features.drop(dropping_features_through_support, axis=1)
    for i in range(0, len(rem)):
        supported_features.insert(i, removals[i], rem[i])
    
    return supported_features

# %% [markdown]
#  ### 3. Now, Applying a ranking method to the features so we can further reduce them . 
# #### First we simply create the rankings, then decide the threshold uptill which we will accept the values
# the feature ranking is based on the values of score,
# - Score = (x-y)/(x+y). 
# - x = % of malware samples that have the feature    
# - y = % of benign samples that have the feature.    
# 
# the higher the absolute value of the score (from 0 to 1), the higher it is in importance for our machine learning algorithms.

# %%

    
def Reduce_by_score(df, score_threshold = 0.2, removals = []):
    score_dropouts = []
    rem = []
    for name in removals:
        rem.append(df[name]); 
        df = df.drop(name, axis=1); 
    # score_threshold = 0.2; #if the score is below this, then this MAY turn out to be not important. 
    allScores = []
    rankreduced_features = df
    totalMal = rankreduced_features['isMalware'].sum()
    totalBen = len(rankreduced_features['isMalware']) - totalMal; 
    for column in rankreduced_features.columns:
        if(column == "isMalware" or column == "Name" or column == "Activities" or column == "Services" or 
        column == "Permissions" or column == "Actions" or column == "receivers" or column == "Categories" ):
            continue

        malSum = 0; 
        benSum = 0;   
        curCol = rankreduced_features[column]
        for i in range(0, len(curCol)):
            if(curCol[i] == 1 and rankreduced_features['isMalware'][i] == 1):
                malSum += 1
            elif(curCol[i] == 1 and rankreduced_features['isMalware'][i] == 0):
                benSum += 1
        
        malPercentage = malSum/totalMal
        benPercentage = benSum/totalBen

        score = (malPercentage - benPercentage)/(malPercentage + benPercentage)
        allScores.append((score, column))

    allScores = sorted(allScores, key=lambda x: abs(x[0]), reverse=True)

    for score, col in allScores:
        if(abs(score) < score_threshold):
            score_dropouts.append(col) #removing this feature in this case.

    rankreduced_features = rankreduced_features.drop(score_dropouts, axis=1)
    for i in range(0, len(rem)):
        rankreduced_features.insert(i, removals[i], rem[i])
    
    return rankreduced_features


# %% [markdown]
# ## Creating multiple experimental featuresets, and later testing accuracy on all of them

# %%
originalDF = pd.read_csv('./Data/ListFeatures/ManifestFeatures.csv')

Reduced = {}
Reduced['Original'] = originalDF


# %%
import gc
del originalDF
gc.collect(); 
Reduced['Original'].shape

# %%
Reduced['Correlation'] = {} 

Reduced['Correlation']['0.95'] = Reduce_by_correlation(originalDF, max_correlation=0.95, removals=['Name', 'isMalware'])
Reduced['Correlation']['0.9'] = Reduce_by_correlation(originalDF, max_correlation=0.9, removals=['Name', 'isMalware'])
Reduced['Correlation']['0.85'] = Reduce_by_correlation(originalDF, max_correlation=0.85, removals=['Name', 'isMalware'])
Reduced['Correlation']['0.8'] = Reduce_by_correlation(originalDF, max_correlation=0.8, removals=['Name', 'isMalware'])
Reduced['Correlation']['0.75'] = Reduce_by_correlation(originalDF, max_correlation=0.75, removals=['Name', 'isMalware'])

for name in Reduced['Correlation']:
    print(name, Reduced['Correlation'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['Correlation'][name].to_csv('./Data/Experimentation/Correlation/Correlation'+name+'.csv', index=False)

# %%
Reduced['Support'] = {}
# We should not go above 0.1. 10% is already quite a lot.
Reduced['Support']['0.1'] = Reduce_by_support(originalDF, min_support=0.1, removals=['Name'])
Reduced['Support']['0.075'] = Reduce_by_support(originalDF, min_support=0.075, removals=['Name'])
# Reduced['Support']['0.05'] = Reduce_by_support(originalDF, min_support=0.05, removals=['Name'])
# Reduced['Support']['0.025'] = Reduce_by_support(originalDF, min_support=0.025, removals=['Name'])

for name in Reduced['Support']:
    print(name, Reduced['Support'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['Support'][name].to_csv('./Data/Experimentation/Support/Support'+name+'.csv', index=False)


# %%
Reduced['Score'] = {}
# 0.8 is probably toO high, but lets see. 
Reduced['Score']['0.8'] = Reduce_by_score(originalDF, score_threshold=0.8, removals=['Name'])
Reduced['Score']['0.6'] = Reduce_by_score(originalDF, score_threshold=0.6, removals=['Name'])
Reduced['Score']['0.4'] = Reduce_by_score(originalDF, score_threshold=0.4, removals=['Name'])
Reduced['Score']['0.2'] = Reduce_by_score(originalDF, score_threshold=0.2, removals=['Name'])

for name in Reduced['Score']:
    print(name, Reduced['Score'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['Score'][name].to_csv('./Data/Experimentation/Score/Score'+name+'.csv', index=False)

# %% [markdown]
# ### Now, Applying the reduction methods by stacking them on top of each other. 

# %%
Reduced['CorrelationSupport'] = {}

for arg0 in Reduced['Correlation']:
    for arg1 in Reduced['Support']:
        Reduced['CorrelationSupport'][arg0+'_'+arg1] = Reduce_by_support(Reduced['Correlation'][arg0], min_support=float(arg1))

for name in Reduced['CorrelationSupport']:
    print(name, Reduced['CorrelationSupport'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['CorrelationSupport'][name].to_csv('./Data/Experimentation/CorrelationSupport/CorrelationSupport'+name+'.csv', index=False)

# %%
Reduced['CorrelationSupportScore'] = {}
for name in Reduced['CorrelationSupport']:
    for i in range(2,7,2):
        k = i/10; 
        Reduced['CorrelationSupportScore'][name+'_'+str(k)] = Reduce_by_score(Reduced['CorrelationSupport'][name], score_threshold=k, removals=['Name'])
    #we also save the corresponding CSV files 
    
for name in Reduced['CorrelationSupportScore']:
    print(name, Reduced['CorrelationSupportScore'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['CorrelationSupportScore'][name].to_csv('./Data/Experimentation/CorrelationSupportScore/CorrelationSupportScore'+name+'.csv', index=False)

# %% [markdown]
# ## Now Visualising one of the featuresets that we have.

# %%
reducedFeatureSet = 0;
try:
    reducedFeatureSet = Reduced['CorrelationSupportScore']['0.75_0.075_0.6']
except Exception as e:
    reducedFeatureSet = pd.read_csv('./Data/Experimentation/CorrelationSupportScore/CorrelationSupportScore0.75_0.075_0.6.csv')
import seaborn as sns 
import matplotlib.pyplot as plt
totalMal = reducedFeatureSet['isMalware'].sum(); 
totalBen = len(reducedFeatureSet['isMalware']) - totalMal; 
featureCount = []
for column in reducedFeatureSet.columns:
    if(column == "isMalware" or column == "Name" ):
        continue
    
    malSum = 0; 
    benSum = 0;   
    curCol = reducedFeatureSet[column]
    for i in range(0, len(curCol)):
        if(curCol[i] == 1 and reducedFeatureSet['isMalware'][i] == 1):
            malSum += 1
        elif(curCol[i] == 1 and reducedFeatureSet['isMalware'][i] == 0):
            benSum += 1
    
    malPercentage = malSum/totalMal
    benPercentage = benSum/totalBen
    featureCount.append((column, malPercentage, benPercentage))

featureCount = sorted(featureCount, key=lambda x: (x[1] - x[2]), reverse=True)
df = pd.DataFrame(featureCount, columns=['Feature', 'Malware', 'Benign'])
benFC = []
for i,j,k in featureCount:
    benFC.append((i,j,"Malware"))
    benFC.append((i,k,"Benign"))

    
df2 = pd.DataFrame(benFC, columns=['Feature', 'Count', 'isMalware'])
fig, ax = plt.subplots(figsize=(10, 10))

sns.barplot(ax=ax,data=df2 ,y='Feature',x = 'Count' , hue='isMalware')
ax.legend()

fig.savefig('./visualisation.png');

# %%



