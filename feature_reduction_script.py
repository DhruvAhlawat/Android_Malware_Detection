# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import time

# %% [markdown]
# ### Reduction methods as functions with parameters are given below.

# %% [markdown]
# ##### 1. Creating a Correlation matrix and detecting highly correlated variables
start_time = time.time(); 
# %%
''' returns a dataframe with all the correlated columns removed. (Only one of them left remaining)
removals is used to remove important columns beforehand and then add them back later after the removal process. (to avoid removing important columns '''
def Reduce_by_correlation(df, max_correlation= 0.9,  removals=[]):
    rem = []
    for name in removals:
        rem.append(df[name]); 
        df = df.drop(name, axis=1); 
    cor_matrix = df.corr(numeric_only=True).abs()
    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))
    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > max_correlation)]
    df = df.drop(df[to_drop], axis=1)
    for i in range(0, len(rem)):
        df.insert(i, removals[i], rem[i])    
    return df


# %% [markdown]
# 

# %% [markdown]
# #### 2. Identifying features that have low support
# We know that features that have low support would not be much useful to us. 
# Even then it may be important to keep features which only appear in malicious apps, even if with very low support as they may be good identifiers of some types of malware. For this we have a danger threshold which states that if the samples which have this feature have this much % of just malware apps, then we do not remove this feature.

# %%

def Reduce_by_support(df, min_support = 0.1, removals=[], label='isMalware'):
    rem = []
    supported_features = df; 

    dropping_features_through_support = []
    totalMal = supported_features[label].sum()
    totalBen = len(supported_features[label]) - totalMal; 

    for column in supported_features.columns:
        if column != label and column not in removals:
            curMal = supported_features[column][supported_features[label] == 1].sum()/totalMal
            curBen = supported_features[column][supported_features[label] == 0].sum()/totalBen
            total = curMal + curBen
            if total < min_support and (curMal < 10*curBen or total < 0.9*min_support):
                dropping_features_through_support.append(column)
    
    supported_features = supported_features.drop(dropping_features_through_support, axis=1)
    
    return supported_features

# %% [markdown]
#  ### 3. Now, Applying a ranking method to the features so we can further reduce them . 
# #### First we simply create the rankings, then decide the threshold uptill which we will accept the values
# the feature ranking is based on the values of score,
# - Score = (x-y)/(x+y). 
# - x = % of malware samples that have the feature    
# - y = % of benign samples that have the feature.    
# 
# the higher the absolute value of the score (from 0 to 1), the higher it is in importance for our machine learning algorithms.

# %%
# np.seterr(all='raise')
    
def Reduce_by_score(df, score_threshold = 0.05,percent_retain = 0.9, removals = [], label = 'isMalware'):
    score_dropouts = []
    rem = []
    rankreduced_features = df
    # score_threshold = 0.2; #if the score is below this, then this MAY turn out to be not important. 
    allScores = []

    totalMal = rankreduced_features['isMalware'].sum()
    totalBen = len(rankreduced_features['isMalware']) - totalMal; 
    for column in rankreduced_features.columns:
        if(column == label or column in removals or column == "Name" or column == "Activities" or column == "Services" or 
        column == "Permissions" or column == "Actions" or column == "receivers" or column == "Categories" ):
            continue
  
        malSum = rankreduced_features[column][rankreduced_features[label] == 1].sum()
        benSum = rankreduced_features[column][rankreduced_features[label] == 0].sum()
        
        malPercentage = malSum/totalMal
        benPercentage = benSum/totalBen
        try:
            score = (malPercentage - benPercentage)/(malPercentage + benPercentage)
            allScores.append((score, column))
        except Exception as e:
            print(e)
            print(column)
            print("malSum: ", malSum, "benSum: ", benSum)
            # raise e; 
            
        

    allScores = sorted(allScores, key=lambda x: abs(x[0]), reverse=True)
    i = 0; 
    size = len(allScores); 
    for score, col in allScores:
        if(abs(score) < score_threshold or i > percent_retain * size):
            score_dropouts.append(col) #removing this feature in this case.
        i += 1; 

    rankreduced_features = rankreduced_features.drop(score_dropouts, axis=1)
    return rankreduced_features


# %% [markdown]
# ## Creating multiple experimental featuresets, and later testing accuracy on all of them

# %%
originalDF = pd.read_csv('~/Documents/Android_Malware_Analysis/Data/ListFeatures/ManifestFeatures.csv')
Label = 'isMalware' #the label column name, may also be Labels
Reduced = {}
Reduced['Original'] = originalDF
originalDF.shape

# %%
Reduced['Support'] = {}
startSup = time.time(); 
# We should not go above 0.1. 10% is already quite a lot.
Reduced['Support']['0.1'] = Reduce_by_support(originalDF, min_support=0.1, removals=['Name'])
Reduced['Support']['0.075'] = Reduce_by_support(originalDF, min_support=0.075, removals=['Name'])
Reduced['Support']['0.05'] = Reduce_by_support(originalDF, min_support=0.05, removals=['Name'])
totalSup = time.time() - startSup; 
print("Total time taken for support reduction: ", totalSup, " seconds"); 

for name in Reduced['Support']:
    print(name, Reduced['Support'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['Support'][name].to_csv('./Data/Experimentation/Support/Support'+name+'.csv', index=False)

# %%
Reduced['Score'] = {}
# 0.8 is probably toO high, but lets see. 
Reduced['Score']['0.25'] = Reduce_by_score(originalDF, score_threshold=0.25, percent_retain=0.75, removals=['Name'])
Reduced['Score']['0.15'] = Reduce_by_score(originalDF, score_threshold=0.15, percent_retain=0.8, removals=['Name'])
Reduced['Score']['0.1'] = Reduce_by_score(originalDF, score_threshold=0.1, percent_retain=0.85, removals=['Name'])
Reduced['Score']['0.05'] = Reduce_by_score(originalDF, score_threshold=0.05, removals=['Name'])

for name in Reduced['Score']:
    print(name, Reduced['Score'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['Score'][name].to_csv('./Data/Experimentation/Score/Score'+name+'.csv', index=False)

# %% [markdown]
# ### Now, Applying the reduction methods by stacking them on top of each other. 

# %%
startSupCor = time.time(); 
Reduced['SupportCorrelation'] = {}
CorrelationList = ['0.75','0.8', '0.85', '0.9', '0.95']
for arg0 in Reduced['Support']:
    for arg1 in CorrelationList:
        Reduced['SupportCorrelation'][arg0+'_'+arg1] = Reduce_by_correlation(Reduced['Support'][arg0], max_correlation=float(arg1))

for name in Reduced['SupportCorrelation']:
    print(name, Reduced['SupportCorrelation'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['SupportCorrelation'][name].to_csv('./Data/Experimentation/CorrelationSupport/SupportCorrelation'+name+'.csv', index=False)

totalSupCorTime = time.time() - startSupCor; 
print("Correlation after Support time taken: ", totalSupCorTime); 
# %%
Reduced['SupportCorrelationScore'] = {}
for name in Reduced['SupportCorrelation']:
    for i in range(2,7,2):
        k = i/10; 
        Reduced['SupportCorrelationScore'][name+'_'+str(k)] = Reduce_by_score(Reduced['SupportCorrelation'][name], score_threshold=k, removals=['Name'])
    #we also save the corresponding CSV files 
    
if(os.path.isdir('./Data/Experimentation/SupportCorrelationScore') == False):
    os.mkdir('./Data/Experimentation/SupportCorrelationScore')
for name in Reduced['SupportCorrelationScore']:
    print(name, Reduced['SupportCorrelationScore'][name].shape)
    #we also save the corresponding CSV files 
    Reduced['SupportCorrelationScore'][name].to_csv('./Data/Experimentation/SupportCorrelationScore/SupportCorrelationScore'+name+'.csv', index=False)

# %% [markdown]
# ## Now Visualising one of the featuresets that we have.

# %%
reducedFeatureSet = 0;
try:
    reducedFeatureSet = Reduced['CorrelationSupportScore']['0.75_0.075_0.6']
except Exception as e:
    reducedFeatureSet = pd.read_csv('./Data/Experimentation/CorrelationSupportScore/CorrelationSupportScore0.75_0.075_0.6.csv')
import seaborn as sns 
import matplotlib.pyplot as plt
totalMal = reducedFeatureSet['isMalware'].sum(); 
totalBen = len(reducedFeatureSet['isMalware']) - totalMal; 
featureCount = []
for column in reducedFeatureSet.columns:
    if(column == "isMalware" or column == "Name" ):
        continue
    
    malSum = 0; 
    benSum = 0;   
    curCol = reducedFeatureSet[column]
    for i in range(0, len(curCol)):
        if(curCol[i] == 1 and reducedFeatureSet['isMalware'][i] == 1):
            malSum += 1
        elif(curCol[i] == 1 and reducedFeatureSet['isMalware'][i] == 0):
            benSum += 1
    
    malPercentage = malSum/totalMal
    benPercentage = benSum/totalBen
    featureCount.append((column, malPercentage, benPercentage))

featureCount = sorted(featureCount, key=lambda x: (x[1] - x[2]), reverse=True)
df = pd.DataFrame(featureCount, columns=['Feature', 'Malware', 'Benign'])
benFC = []
for i,j,k in featureCount:
    benFC.append((i,j,"Malware"))
    benFC.append((i,k,"Benign"))

    
df2 = pd.DataFrame(benFC, columns=['Feature', 'Count', 'isMalware'])
fig, ax = plt.subplots(figsize=(10, 10))

sns.barplot(ax=ax,data=df2 ,y='Feature',x = 'Count' , hue='isMalware')
ax.legend()

fig.savefig('someReduction.png')

end_time = time.time(); 

print(); 

print("Total Time taken: ", end_time - start_time) 

# %%



