# %%
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from tensorflow import keras
from sklearn.model_selection import train_test_split
import tensorflow_decision_forests as tfdf
import math
import tensorflow as tf
# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# %%
DataDict = {}
directory = '/kaggle/input/correlationsupportscore'
for file in os.listdir(directory):
    DataDict[file] = pd.read_csv(os.path.join(directory, file))


# %%
df_train = {}; df_test = {};

for data in DataDict:
    df_train[data], df_test[data] = train_test_split(DataDict[data], test_size=0.20, random_state=5) #, random_state=5)
    
train_ds = {}; test_ds = {};
for i in DataDict:
    train_ds[i] = tfdf.keras.pd_dataframe_to_tf_dataset(df_train[i], label = "isMalware")
    test_ds[i] = tfdf.keras.pd_dataframe_to_tf_dataset(df_test[i], label = "isMalware")


# %% [markdown]
# ## Now, Training the random forest model on the different datasets, and noting the time taken for each.

# %%
import time
from datetime import timedelta


ForestModel = {};
timeTaken = {} 
for i in DataDict:
    start_time = time.monotonic()
    ForestModel[i] = tfdf.keras.RandomForestModel(verbose=0)
#Training the model
    ForestModel[i].fit(train_ds[i])
    end_time = time.monotonic()
    timeTaken[i] = timedelta(seconds=end_time-start_time)

# %%
for i in ForestModel:
    start_time = time.monotonic()
    ForestModel[i].compile(metrics=["accuracy", "FalsePositives", "FalseNegatives", "TruePositives", "TrueNegatives", "Precision", "Recall"])
    evaluation = ForestModel[i].evaluate(test_ds[i], return_dict=True)
    end_time = time.monotonic()
    print()
    print("Dataset: {}, Number of features: {}, time to train: {}, time to evaluate: {}".format(i, DataDict[i].shape[1], timeTaken[i],end_time - start_time  ))
    for name, value in evaluation.items():
        if(name == "accuracy" and value < 0.9):
            break
        print(f"{name}: {value:.4f}")

# %%
Accuracy = []
Precision = []
Recall = []

for i in ForestModel:
    start_time = time.monotonic()
    ForestModel[i].compile(metrics=["accuracy", "FalsePositives", "FalseNegatives", "TruePositives", "TrueNegatives", "Precision", "Recall"])
    evaluation = ForestModel[i].evaluate(test_ds[i], return_dict=True)
    end_time = time.monotonic()
#     print("Dataset: {}, Number of features: {}, time to train: {}, time to evaluate: {}".format(i, DataDict[i].shape[1], timeTaken[i],end_time - start_time  ))
    for name, value in evaluation.items():
        if(name == "accuracy"):
            Accuracy.append((DataDict[i].shape[1], value))
        if(name == "precision"):
            Precision.append((DataDict[i].shape[1], value))
        if(name == "recall"):
            Recall.append((DataDict[i].shape[1], value))
            


# %%
import matplotlib.pyplot as plt
# %matplotlib inline

fig, ax = plt.subplots()
xA = [a[0] for a in Accuracy]
yA = [a[1] for a in Accuracy]
xP = [a[0] for a in Precision]
yP = [a[1] for a in Precision]
xR = [a[0] for a in Recall]
yR = [a[1] for a in Recall]

ax.scatter(xA,yA, alpha=0.7, color='crimson', edgecolors='none', label = 'accuracy')
ax.scatter(xP,yP, alpha = 0.6, color='blue', label = 'precision')
ax.scatter(xR, yR, alpha = 0.7, color='green', label = 'recall')

ax.legend()
plt.title('Scatter plot')
ax.set_xlabel('Number of features')
ax.set_ylabel('Value')


# %%
fig.savefig('ReductionData')

# %%



