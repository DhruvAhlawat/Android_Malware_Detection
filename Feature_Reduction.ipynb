{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction methods as functions with parameters are given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Creating a Correlation matrix and detecting highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' returns a dataframe with all the correlated columns removed. (Only one of them left remaining)\n",
    "removals is used to remove important columns beforehand and then add them back later after the removal process. (to avoid removing important columns '''\n",
    "def Reduce_by_correlation(df, max_correlation= 0.9,  removals=[]):\n",
    "    rem = []\n",
    "    for name in removals:\n",
    "        rem.append(df[name]); \n",
    "        df = df.drop(name, axis=1); \n",
    "    cor_matrix = df.corr().abs()\n",
    "    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > max_correlation)]\n",
    "    df = df.drop(df[to_drop], axis=1)\n",
    "    for i in range(0, len(rem)):\n",
    "        df.insert(i, removals[i], rem[i])    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Identifying features that have low support\n",
    "We know that features that have low support would not be much useful to us. \n",
    "Even then it may be important to keep features which only appear in malicious apps, even if with very low support as they may be good identifiers of some types of malware. For this we have a danger threshold which states that if the samples which have this feature have this much % of just malware apps, then we do not remove this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Reduce_by_support( df, min_support = 0.1, removals=[],danger_threshold = 0.95, should_drop_possibly_dangerous = True):\n",
    "    rem = []\n",
    "    for name in removals:\n",
    "        rem.append(df[name]); \n",
    "        df = df.drop(name, axis=1); \n",
    "    \n",
    "    supported_features = df; \n",
    "    dropping_features_through_support = []\n",
    "\n",
    "    # possibly_dangerous_features = []; \n",
    "    #if malware/(benign + malware) is greater than this ratio, then we can classify it as a potentially dangerous feature.\n",
    "\n",
    "    #if this is set to true, then we will drop the low support features even if they are labelled as possibly dangerous.\n",
    "    totalMal = supported_features['isMalware'].sum()\n",
    "    totalBen = len(supported_features['isMalware']) - totalMal; \n",
    "\n",
    "    possibly_dangerous_features  =[] \n",
    "    for column in supported_features.columns:\n",
    "        if(column == \"isMalware\" or column == \"Name\" or column == \"Activities\" or column == \"Services\" or \n",
    "        column == \"Permissions\" or column == \"Actions\" or column == \"receivers\" or column == \"Categories\" ):\n",
    "            continue #we don't want to remove these columns anyway. \n",
    "        malSum = 0; \n",
    "        benSum = 0;   \n",
    "        curCol = supported_features[column]\n",
    "        for i in range(0, len(curCol)):\n",
    "            if(curCol[i] == 1 and supported_features['isMalware'][i] == 1):\n",
    "                malSum += 1\n",
    "            elif(curCol[i] == 1 and supported_features['isMalware'][i] == 0):\n",
    "                benSum += 1\n",
    "        \n",
    "        dangerProb = (malSum/totalMal) / (malSum/totalMal + benSum/totalBen) \n",
    "        #now that we know the individual sums for malwares and benign applications, we can further reduce the features by thus deciding on a threshold.\n",
    "        if(dangerProb >= danger_threshold):\n",
    "            possibly_dangerous_features.append(column)\n",
    "        if(malSum + benSum < min_support*supported_features.shape[0]):\n",
    "            if((benSum >= malSum*(1-danger_threshold)) and not should_drop_possibly_dangerous) or (should_drop_possibly_dangerous == True):\n",
    "                dropping_features_through_support.append(column)\n",
    "\n",
    "    supported_features = supported_features.drop(dropping_features_through_support, axis=1)\n",
    "    for i in range(0, len(rem)):\n",
    "        supported_features.insert(i, removals[i], rem[i])\n",
    "    \n",
    "    return supported_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Now, Applying a ranking method to the features so we can further reduce them . \n",
    "#### First we simply create the rankings, then decide the threshold uptill which we will accept the values\n",
    "the feature ranking is based on the values of score,\n",
    "- Score = (x-y)/(x+y). \n",
    "- x = % of malware samples that have the feature    \n",
    "- y = % of benign samples that have the feature.    \n",
    "\n",
    "the higher the absolute value of the score (from 0 to 1), the higher it is in importance for our machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def Reduce_by_score(df, score_threshold = 0.2, removals = []):\n",
    "    score_dropouts = []\n",
    "    rem = []\n",
    "    for name in removals:\n",
    "        rem.append(df[name]); \n",
    "        df = df.drop(name, axis=1); \n",
    "    # score_threshold = 0.2; #if the score is below this, then this MAY turn out to be not important. \n",
    "    allScores = []\n",
    "    rankreduced_features = df\n",
    "    totalMal = rankreduced_features['isMalware'].sum()\n",
    "    totalBen = len(rankreduced_features['isMalware']) - totalMal; \n",
    "    for column in rankreduced_features.columns:\n",
    "        if(column == \"isMalware\" or column == \"Name\" or column == \"Activities\" or column == \"Services\" or \n",
    "        column == \"Permissions\" or column == \"Actions\" or column == \"receivers\" or column == \"Categories\" ):\n",
    "            continue\n",
    "\n",
    "        malSum = 0; \n",
    "        benSum = 0;   \n",
    "        curCol = rankreduced_features[column]\n",
    "        for i in range(0, len(curCol)):\n",
    "            if(curCol[i] == 1 and rankreduced_features['isMalware'][i] == 1):\n",
    "                malSum += 1\n",
    "            elif(curCol[i] == 1 and rankreduced_features['isMalware'][i] == 0):\n",
    "                benSum += 1\n",
    "        \n",
    "        malPercentage = malSum/totalMal\n",
    "        benPercentage = benSum/totalBen\n",
    "\n",
    "        score = (malPercentage - benPercentage)/(malPercentage + benPercentage)\n",
    "        allScores.append((score, column))\n",
    "\n",
    "    allScores = sorted(allScores, key=lambda x: abs(x[0]), reverse=True)\n",
    "\n",
    "    for score, col in allScores:\n",
    "        if(abs(score) < score_threshold):\n",
    "            score_dropouts.append(col) #removing this feature in this case.\n",
    "\n",
    "    rankreduced_features = rankreduced_features.drop(score_dropouts, axis=1)\n",
    "    for i in range(0, len(rem)):\n",
    "        rankreduced_features.insert(i, removals[i], rem[i])\n",
    "    \n",
    "    return rankreduced_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating multiple experimental featuresets, and later testing accuracy on all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalDF = pd.read_csv('~/Documents/Android_Malware_Analysis/Data/ListFeatures/ManifestFeatures.csv')\n",
    "\n",
    "Reduced = {}\n",
    "Reduced['Original'] = originalDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del originalDF\n",
    "# gc.collect(); \n",
    "Reduced['Original'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduced['Correlation'] = {} \n",
    "\n",
    "Reduced['Correlation']['0.95'] = Reduce_by_correlation(originalDF, max_correlation=0.95, removals=['Name', 'isMalware'])\n",
    "Reduced['Correlation']['0.9'] = Reduce_by_correlation(originalDF, max_correlation=0.9, removals=['Name', 'isMalware'])\n",
    "Reduced['Correlation']['0.85'] = Reduce_by_correlation(originalDF, max_correlation=0.85, removals=['Name', 'isMalware'])\n",
    "Reduced['Correlation']['0.8'] = Reduce_by_correlation(originalDF, max_correlation=0.8, removals=['Name', 'isMalware'])\n",
    "Reduced['Correlation']['0.75'] = Reduce_by_correlation(originalDF, max_correlation=0.75, removals=['Name', 'isMalware'])\n",
    "\n",
    "for name in Reduced['Correlation']:\n",
    "    print(name, Reduced['Correlation'][name].shape)\n",
    "    #we also save the corresponding CSV files \n",
    "    Reduced['Correlation'][name].to_csv('./Data/Experimentation/Correlation/Correlation'+name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduced['Support'] = {}\n",
    "# We should not go above 0.1. 10% is already quite a lot.\n",
    "Reduced['Support']['0.1'] = Reduce_by_support(originalDF, min_support=0.1, removals=['Name'])\n",
    "Reduced['Support']['0.075'] = Reduce_by_support(originalDF, min_support=0.075, removals=['Name'])\n",
    "Reduced['Support']['0.05'] = Reduce_by_support(originalDF, min_support=0.05, removals=['Name'])\n",
    "# Reduced['Support']['0.025'] = Reduce_by_support(originalDF, min_support=0.025, removals=['Name'])\n",
    "\n",
    "for name in Reduced['Support']:\n",
    "    print(name, Reduced['Support'][name].shape)\n",
    "    #we also save the corresponding CSV files \n",
    "    Reduced['Support'][name].to_csv('./Data/Experimentation/Support/Support'+name+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduced['Score'] = {}\n",
    "# 0.8 is probably toO high, but lets see. \n",
    "Reduced['Score']['0.8'] = Reduce_by_score(originalDF, score_threshold=0.8, removals=['Name'])\n",
    "Reduced['Score']['0.6'] = Reduce_by_score(originalDF, score_threshold=0.6, removals=['Name'])\n",
    "Reduced['Score']['0.4'] = Reduce_by_score(originalDF, score_threshold=0.4, removals=['Name'])\n",
    "Reduced['Score']['0.2'] = Reduce_by_score(originalDF, score_threshold=0.2, removals=['Name'])\n",
    "\n",
    "for name in Reduced['Score']:\n",
    "    print(name, Reduced['Score'][name].shape)\n",
    "    #we also save the corresponding CSV files \n",
    "    Reduced['Score'][name].to_csv('./Data/Experimentation/Score/Score'+name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, Applying the reduction methods by stacking them on top of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduced['CorrelationSupport'] = {}\n",
    "\n",
    "for arg0 in Reduced['Correlation']:\n",
    "    for arg1 in Reduced['Support']:\n",
    "        Reduced['CorrelationSupport'][arg0+'_'+arg1] = Reduce_by_support(Reduced['Correlation'][arg0], min_support=float(arg1))\n",
    "\n",
    "for name in Reduced['CorrelationSupport']:\n",
    "    print(name, Reduced['CorrelationSupport'][name].shape)\n",
    "    #we also save the corresponding CSV files \n",
    "    Reduced['CorrelationSupport'][name].to_csv('./Data/Experimentation/CorrelationSupport/CorrelationSupport'+name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduced['CorrelationSupportScore'] = {}\n",
    "for name in Reduced['CorrelationSupport']:\n",
    "    for i in range(2,7,2):\n",
    "        k = i/10; \n",
    "        Reduced['CorrelationSupportScore'][name+'_'+str(k)] = Reduce_by_score(Reduced['CorrelationSupport'][name], score_threshold=k, removals=['Name'])\n",
    "    #we also save the corresponding CSV files \n",
    "    \n",
    "for name in Reduced['CorrelationSupportScore']:\n",
    "    print(name, Reduced['CorrelationSupportScore'][name].shape)\n",
    "    #we also save the corresponding CSV files \n",
    "    Reduced['CorrelationSupportScore'][name].to_csv('./Data/Experimentation/CorrelationSupportScore/CorrelationSupportScore'+name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Visualising one of the featuresets that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedFeatureSet = 0;\n",
    "try:\n",
    "    reducedFeatureSet = Reduced['CorrelationSupportScore']['0.75_0.075_0.6']\n",
    "except Exception as e:\n",
    "    reducedFeatureSet = pd.read_csv('./Data/Experimentation/CorrelationSupportScore/CorrelationSupportScore0.75_0.075_0.6.csv')\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "totalMal = reducedFeatureSet['isMalware'].sum(); \n",
    "totalBen = len(reducedFeatureSet['isMalware']) - totalMal; \n",
    "featureCount = []\n",
    "for column in reducedFeatureSet.columns:\n",
    "    if(column == \"isMalware\" or column == \"Name\" ):\n",
    "        continue\n",
    "    \n",
    "    malSum = 0; \n",
    "    benSum = 0;   \n",
    "    curCol = reducedFeatureSet[column]\n",
    "    for i in range(0, len(curCol)):\n",
    "        if(curCol[i] == 1 and reducedFeatureSet['isMalware'][i] == 1):\n",
    "            malSum += 1\n",
    "        elif(curCol[i] == 1 and reducedFeatureSet['isMalware'][i] == 0):\n",
    "            benSum += 1\n",
    "    \n",
    "    malPercentage = malSum/totalMal\n",
    "    benPercentage = benSum/totalBen\n",
    "    featureCount.append((column, malPercentage, benPercentage))\n",
    "\n",
    "featureCount = sorted(featureCount, key=lambda x: (x[1] - x[2]), reverse=True)\n",
    "df = pd.DataFrame(featureCount, columns=['Feature', 'Malware', 'Benign'])\n",
    "benFC = []\n",
    "for i,j,k in featureCount:\n",
    "    benFC.append((i,j,\"Malware\"))\n",
    "    benFC.append((i,k,\"Benign\"))\n",
    "\n",
    "    \n",
    "df2 = pd.DataFrame(benFC, columns=['Feature', 'Count', 'isMalware'])\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.barplot(ax=ax,data=df2 ,y='Feature',x = 'Count' , hue='isMalware')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
